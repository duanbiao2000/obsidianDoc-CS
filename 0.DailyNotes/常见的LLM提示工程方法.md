
1. **系统提示（System Prompting）**：用于设置模型的整体上下文和目的，定义模型的基本能力和主要任务，可控制输出结构或安全性等。例如，指令“仅返回大写的情感标签”，模型在面对电影评论时，会以大写形式输出情感标签，如“NEGATIVE”。
2. **角色提示（Role Prompting）**：为模型分配特定角色，使其生成与角色一致的内容。适用于需要特定风格或专业知识的回答场景，如客服、教育等领域。例如，指令“扮演旅行指南，推荐阿姆斯特丹的3个博物馆”，模型会以旅行指南的角色来推荐相关博物馆。
3. **上下文提示（Contextual Prompting）**：提供与当前任务相关的具体细节或背景信息，帮助模型理解请求并生成相关响应。适用于需要个性化或领域相关输出的场景，如内容创作。例如，告知模型“你正在为复古游戏博客撰稿”，然后请求“建议3个文章主题”，模型会根据复古游戏博客的背景来提供主题建议。
4. **逐步回退提示（Step - Back Prompting）**：首先让LLM考虑一个与具体任务相关的通用问题，然后将答案反馈到后续的具体任务提示中，以激活相关的背景知识和推理过程。适用于复杂任务需激活背景知识的场景，如游戏设计、学术研究等。例如，先问“FPS游戏中哪些设定能创造挑战性？”，再基于此问“基于‘废弃军事基地’设定写剧情”。
5. **链式思维提示（Chain - of - Thought Prompting，CoT）**：引导模型逐步进行推理，将问题分解为更小、更易处理的子问题，通过产生一系列中间推理步骤，增强模型进行复杂推理的能力。适用于数学问题、逻辑推理或需解释的任务。例如，对于“我3岁时伴侣年龄是我的3倍，现在20岁，伴侣几岁?”的问题，模型会分步计算年龄差后得出答案。
6. **自我一致性提示（Self - Consistency）**：通过生成多样的推理路径并选择最常见的答案来提高响应的准确性和一致性。适用于减少随机性，提高答案可靠性的场景，如分类、评估等。例如，多次提问分类邮件是否为重要，最终选择多数结果作为答案。
7. **思维树提示（Tree of Thoughts，ToT）**：允许LLM同时探索多个不同的推理路径，特别适用于需多角度分析的复杂问题，如策略规划、创意生成等。
8. **ReAct提示（Reason & Act）**：结合推理和外部工具，如搜索API、代码解释器等，来解决问题，模拟人类在现实世界中的操作方式。适用于需要实时数据或交互的任务，如信息检索、代码执行等。例如，对于“Metallica乐队成员共有多少孩子?”的任务，模型会分步搜索每位成员信息并累加得出结果。